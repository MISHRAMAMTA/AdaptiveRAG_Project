{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings,ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import Document\n",
    "from langchain import hub\n",
    "\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import List\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load enviornmental variable\n",
    "load_dotenv()\n",
    "\n",
    "#key setup\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.load()\n",
    "#Load Document\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs=[WebBaseLoader(url).load() for url in urls]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create Retriver\n",
    "2. create route function to check if the vectorstore have the document relevent to question\n",
    "3. check if document is relevent generate answer (generation function) if not transform query\n",
    "4. check if answer is hellusinating or not if not and if answer is relevent end\n",
    "5. if hellucinating send generate again answer, if not relevent transform query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.split_documents(), .from_documents, .as_retriver\n",
    "#split the document\n",
    "doc_list=[doc for sublist in docs for doc in sublist]\n",
    "text_spliter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_doc=text_spliter.split_documents(doc_list)\n",
    "#embedding and then creation of vector database\n",
    "Embedding=OpenAIEmbeddings()\n",
    "vectorstore=FAISS.from_documents(documents=split_doc, embedding=Embedding)\n",
    "#Retriver\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "    route_selection:Literal[\"vectorstore\",\"Websearch\"]=Field(\n",
    "        discription=\"Decide weather to use vectorstore or websearch\")\n",
    "\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_withstructure=llm.with_structured_output(RouteQuery)\n",
    "\n",
    "sys=\"\"\"You are an assistant that decides the best source for answering a user’s question.\n",
    "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
    "route_prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",sys),\n",
    "    (\"human\",\"the user question is {question}\")\n",
    "    ])\n",
    "\n",
    "route_llm= route_prompt|llm_withstructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocRelevant(BaseModel):\n",
    "    doc_relevant : Literal[\"relevant\", \"irrelevant\"] = Field(\n",
    "        description=\"Decide if the retrieved document from the vectorstore is relevant to the question. Select either 'relevant' or 'irrelevant'.\"\n",
    "    )\n",
    "\n",
    "sys = \"\"\"You are a grader assessing the relevance of a retrieved document to a user's question.\n",
    "If the retrieved document contains keywords or semantic meaning related to the question, grade it as 'relevant'. \n",
    "Otherwise, grade it as 'irrelevant'.\n",
    "The goal is to filter out unrelated documents.\n",
    "\"\"\"\n",
    "\n",
    "DocRelevance_Prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys),\n",
    "    (\"human\", \"User question:\\n{question}\\n\\nDocument content:\\n{document}\")\n",
    "])\n",
    "\n",
    "llm_withstructure = llm.with_structured_output(GradeDocRelevant)\n",
    "\n",
    "Doc_relevance_llm = DocRelevance_Prompt | llm_withstructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedQuery(BaseModel):\n",
    "    query: str = Field(description=\"Rewrite the question to improve clarity\")\n",
    "\n",
    "# System prompt\n",
    "sys_prompt = \"\"\"\n",
    "You are an expert at rewriting user queries to improve clarity and optimize them for vectorstore retrieval.\n",
    "Analyze the input question and rewrite it to capture the true semantic intent.\n",
    "Return only the improved and retrieval-ready query.\n",
    "\"\"\"\n",
    "\n",
    "# ChatPrompt\n",
    "transformed_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_prompt),\n",
    "    (\"human\", \"User question:\\n{question}\")\n",
    "])\n",
    "\n",
    "# Structured LLM\n",
    "llm_withstructure = llm.with_structured_output(TransformedQuery)\n",
    "\n",
    "# Final LLM chain\n",
    "transformed_query_llm = transformed_prompt | llm_withstructure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/58cswsf121l0qymv21qbtb500000gn/T/ipykernel_12957/2998626336.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  websearch_tool=TavilySearchResults(k=3)\n"
     ]
    }
   ],
   "source": [
    "websearch_tool=TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate \n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "generate_llm=prompt| llm| StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hellucination\n",
    "class GradeHellucination(BaseModel):\n",
    "    binary_response:Literal[\"yes\", \"no\"]=Field(description=\"Decide if the llm generation is grounded in the facts\")\n",
    "\n",
    "llm_withstructure=llm.with_structured_output(GradeHellucination)\n",
    "\n",
    "sys=\"\"\"You are an AI assistant that help in deciding, whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "Hellucination_prompt=ChatPromptTemplate([\n",
    "    (\"system\", sys),\n",
    "    (\"human\", \"The answer is:{generation}, \\n\\n supporting documents are: {documents}\")\n",
    "])\n",
    "\n",
    "hellucination_llm=Hellucination_prompt|llm_withstructure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer Relevance\n",
    "class GradeAnswerRelevance(BaseModel):\n",
    "    binary_response:Literal[\"yes\", \"no\"]=Field(description=\"Answer addresses the question, 'yes' or 'no'\")\n",
    "\n",
    "llm_withstructure=llm.with_structured_output(GradeAnswerRelevance)\n",
    "\n",
    "sys=\"\"\"You are a grader decide weather the answer resolve the question or not. 'yes, means the answer resolve the question.\"\"\"\n",
    "\n",
    "relevant_prompt=ChatPromptTemplate([\n",
    "    (\"system\", sys),\n",
    "    (\"human\", \"The answer is:{generation}, \\n\\n the question is: {question}\")\n",
    "])\n",
    "\n",
    "relevant_llm=relevant_prompt|llm_withstructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Nodes\n",
    "class State(TypedDict):\n",
    "    question:str\n",
    "    documents:List[str]\n",
    "    generation:str\n",
    "\n",
    "\n",
    "def retrieve(state:State):\n",
    "    retrieve_doc=retriever.invoke(state[\"question\"])\n",
    "    return {\"documents\":retrieve_doc, \"question\":question}\n",
    "    print(\"step1\")\n",
    "\n",
    "\n",
    "def route(state:State):\n",
    "    route_decision=route_llm.invoke({\"question\":state[\"question\"]})\n",
    "    if route_decision.route_selection==\"vectorstore\":\n",
    "        return \"vectorstore\"\n",
    "    \n",
    "    elif route_decision.route_selection==\"Websearch\":\n",
    "        return \"Websearch\"\n",
    "\n",
    "def docRelevence(state:State):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = Doc_relevance_llm.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade=score.doc_relevant\n",
    "        if grade == \"relevant\":\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "    \n",
    "    \n",
    "def relevent_doc(state:State):\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transfer_query\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    \n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def generate(state:State):\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    context_text = format_docs(documents)\n",
    "    answer=generate_llm.invoke({\"context\":context_text, \"question\":question})\n",
    "    print(\"step3\")\n",
    "    return {\"generation\":answer, \"question\":question, \"documents\":documents}\n",
    "\n",
    "def transfer_query(state:State):\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    context_text = format_docs(documents)\n",
    "    transformed_query=transformed_query_llm.invoke({\"documents\":context_text, \"question\":question})\n",
    "    print(\"step4\")\n",
    "    return {\"question\":transformed_query.query, \"documents\":documents}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = websearch_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = [Document(page_content=web_results)]\n",
    "\n",
    "    return {\"documents\": web_results, \"question\": question}\n",
    "\n",
    "\n",
    "def conditions(state:State):\n",
    "    hellucination_response= hellucination_llm.invoke({\"generation\":state[\"generation\"], \"documents\":state[\"documents\"]})\n",
    "    relevance_response=relevant_llm.invoke({\"generation\":state[\"generation\"], \"question\":state[\"question\"]})\n",
    "\n",
    "    if hellucination_response.binary_response==\"yes\":\n",
    "        print(\"step7\")\n",
    "        if relevance_response.binary_response==\"yes\":\n",
    "            return \"useful_response\"\n",
    "        else:\n",
    "            print(\"step9\")\n",
    "            return \"transfer_query\"\n",
    "    else:\n",
    "        print(\"step8\")\n",
    "        return \"generate\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow=StateGraph(State)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"Websearch\", web_search)\n",
    "workflow.add_node(\"transfer_query\", transfer_query)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"docRelevence\", docRelevence)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    START, \n",
    "    route,\n",
    "    {\"vectorstore\":\"retrieve\",\n",
    "    \"Websearch\":\"Websearch\"}\n",
    "    )\n",
    "\n",
    "workflow.add_edge(\"retrieve\",\"docRelevence\")\n",
    "workflow.add_edge(\"Websearch\",\"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"docRelevence\",\n",
    "    relevent_doc,\n",
    "    {\"transfer_query\":\"transfer_query\",\n",
    "    \"generate\":\"generate\"}\n",
    "    )\n",
    "workflow.add_edge(\"transfer_query\",\"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    conditions,\n",
    "    {\"transfer_query\":\"transfer_query\",\n",
    "    \"useful_response\":END,\n",
    "    \"generate\":\"generate\"})\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATE---\n",
      "step3\n",
      "step7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'agent memory',\n",
       " 'documents': [Document(id='b6390757-607d-4717-991c-ec88a8a90fbd', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)'),\n",
       "  Document(id='213d2242-fc78-4c56-be17-071e98b9bfec', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
       "  Document(id='9cc2fcd4-4eb6-49a3-8fe9-cf8f730e889a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\n\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
       "  Document(id='c0d1eae0-2c80-47c6-aa55-56a34aa79d6e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.')],\n",
       " 'generation': 'Agent memory consists of short-term and long-term memory systems. Short-term memory involves in-context learning, while long-term memory utilizes an external database to retain and recall information over extended periods. This structure allows agents to synthesize experiences and inform future behavior based on past events.'}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"question\":\"What is agent memory\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---WEB SEARCH---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is badminton?',\n",
       " 'documents': [Document(metadata={}, page_content='What is badminton?Badminton is a sport in which light rackets are used to volley an object—called a shuttlecock, shuttle, birdie, or bird—back and forth over a high net.Unlike other similar sports, such as tennis, badminton is not played with a ball—the shuttlecock is a kind of feathered cone with a cork head. (A shuttlecock is also used in the related sport of battledore).Competitive badminton, which is featured as an event in the Olympic Games, is played on an indoor court and can consist of [...] 1. a game played on a rectangular court by two players or two pairs of players equipped with light rackets used to volley a shuttlecock over a high net that divides the court in half.\\n\\nbadminton\\n\\n1\\n\\n/ ˈbædmɪntən/\\n\\n## noun\\n\\n1. a game played with rackets and a shuttlecock, which is hit back and forth across a high net\\n2. Also called:badminton cup. a long refreshing drink of claret with soda water and sugar\\n\\nBadminton\\n\\n2\\n\\n/ ˈbædmɪntən/\\n\\n## noun [...] one-on-one play or doubles. The rules of badminton are similar to those of other sports that use nets, like tennis and volleyball: if a player hits the shuttlecock out of bounds or lets it touch the ground on their side of the court, their opponent(s) get a point.Badminton is also played recreationally, often as a casual yard game with multiplayer teams (less casual if Uncle Tahir is on your team).Example: You’ll see some lightning-quick reflexes in Olympic-level badminton.\\nBadminton is a racquet sport played using racquets \"Racket (sports equipment)\") to hit a shuttlecock across a net \"Net (device)\"). Although it may be played with larger teams, the most common forms of the game are \"singles\" (with one player per side) and \"doubles\" (with two players per side). Badminton is often played as a casual outdoor activity in a yard \"Yard (land)\") or on a beach; professional games are played on a rectangular indoor court. Points are scored by striking the shuttlecock [...] The game developed in British India from the earlier game of battledore and shuttlecock. European play came to be dominated by Denmark but the game has become very popular in Asia. In 1992, badminton debuted as a Summer Olympic sport with four events: men\\'s singles, women\\'s singles, men\\'s doubles, and women\\'s doubles; mixed doubles was added four years later. At high levels of play, the sport demands excellent fitness: players require aerobic stamina, agility, strength, speed, and precision. It [...] is also a technical sport, requiring good motor coordination and the development of sophisticated racquet movements involving much greater flexibility in the wrist than some other racquet sports.\\nBadminton is a racket sport played by either two opposing players (singles) or two opposing pairs (doubles), who take positions on opposite halves of a rectangular court that is divided by a net. Players score points by striking a shuttlecock with their racket so that it passes over the net and lands in their opponents\\' half of the court. A rally ends once the shuttlecock has struck the ground, and the shuttlecock may only be struck once by each side before it passes over the net. [...] Since 1992, badminton has been an Olympic sport with five events: men\\'s and women\\'s singles, men\\'s and women\\'s doubles, and mixed doubles, in which each pair is a man and a woman. At high levels of play, the sport demands excellent fitness: players require aerobic stamina, agility, strength, speed, and precision. It is also a technical sport, requiring good motor coordination and the development of sophisticated racket movements.\\n\\n(Source: \\n\\nFor Badminton Rules and Regulations click here.\\nBadminton is an indoor sport played by two opposing players (singles) or two pairs (doubles), who use a shuttlecock during a rally to try to land it on their opponents’ court or force an error. A match is played in a best-of-three games format. To win the match, a player must secure two out of three games, each played to 21 points. Additionally, a player must achieve a 2-point advantage to win a game. If that advantage is not reached, the first player to score 30 points wins the game. Points\\nBadminton is a racket sport that originated in ancient Greece, China and India. It became popularized in England in the 1860s and the modern rules were established in 1873 at Badminton House in Gloucestershire. It involves hitting a shuttlecock back and forth over a net using rackets. The game is played individually or as doubles teams and features skills like clears, smashes, drives and drops shots. Points are scored on each serve and matches are best of three games to 21 points. [...] Dr. Teejay D. Panganiban, LPT, MPES, DEMCourse Professor\\n\\nDownload to read ad-free\\n\\nBADMINTON is a racket sport played by either twoopposing players (singles) or two opposing pairs(doubles).\\n\\n✔\\n\\nCompetitive badminton is best played indoorsbecause shuttlecock flight is affected by wind. Butbadminton, as a casual recreational activity, canalso be played outdoors.\\n\\n✔\\n\\nBadminton has been an Olympic sport since 1992(Barcelona).\\n\\nNature of the Game\\n\\nDownload to read ad-free\\n\\n✔ [...] 0 ratings0% found this document useful (0 votes)\\n\\n9K views39 pages\\n\\nModule 4 - Badminton - History, Basic Skills, Equipment, Rules and Regulations\\n\\nBadminton is a racket sport that originated in ancient Greece, China and India. It became popularized in England in the 1860s and the modern rules were established in 1873 at Badminton House…\\n\\n## Uploaded by\\n\\nTeejay Panganiban\\n\\nDownload as pdf or txt\\n\\nYou are on page 1/ 39\\n\\nIndividual and Dual Sports')],\n",
       " 'generation': \"Badminton is a racket sport played by either two players (singles) or two pairs (doubles) who hit a shuttlecock over a high net. The objective is to score points by landing the shuttlecock in the opponent's court or forcing an error. It has been an Olympic sport since 1992 and requires skills such as agility, precision, and good motor coordination.\"}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"question\":\"What is badminton?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
